{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"COMP2825 - Computer Architecture and Organization","text":""},{"location":"#overview","title":"Overview","text":"<p>For full course information COMP 2825 - BCIT Course taken in Fall 2025 term (outline) with Rahim Oraji.</p> <ul> <li>Midterm and Final in-person</li> <li>weekly quizes</li> <li>weekly labs<ul> <li>each lab will involve two things:<ul> <li>watching a video and writing a one page summary (what is this, high school?)</li> <li>answering questions based on the slides</li> <li>only given 5 days for the labs because reasons</li> </ul> </li> </ul> </li> </ul>"},{"location":"wk_one/","title":"Week 1","text":""},{"location":"wk_one/#computer-architecture","title":"Computer Architecture","text":"<p>Computer Architecture: The study of how to design the parts of a computer  system visible to programmers, including the instruction set, memory hierarchy, and execution model (e.g., pipelined execution).</p> <p>Computer organization: Focuses on the internal structure of hardware  components like ALUs, registers, and buses.</p> <p>In practice, both used interchangably.</p> <p>Studying computer architecture helps us understand:</p> <ul> <li>code implementation,</li> <li>performance optimization,</li> <li>concepts such as parallelism, caching, and pipelining,</li> <li>tradeoffs between hardware and software design choices</li> </ul>"},{"location":"wk_one/#computers-and-programs","title":"Computers and Programs","text":"<p>A computer executes given instructions (programs) to produce results for  the user.</p>"},{"location":"wk_one/#program-execution","title":"Program Execution","text":"<p>In general, when it comes to executing a given program, there are two methods:</p> <ol> <li>Translation (compilation)<ul> <li>Converts a high-level program into a low-level (machine code) version  before execution</li> </ul> </li> <li>Interpretation<ul> <li>A low-level machine program (the interpreter) reads and executes  high-level programs instruction by instruction during runtime. </li> </ul> </li> </ol>"},{"location":"wk_one/#program-languages-and-levels","title":"Program Languages and Levels","text":"<p>A program is a set of instructions written in a high level programming language.</p> <ol> <li> <p>Machine Language (low level) Raw binary code (zeros and ones) executed directly by the CPU.  </p> </li> <li> <p>Human-Readable Machine Language Uses mnemonics instead of binary, but still closely tied to hardware.      Each instruction maps directly to machine code.  Example: Assembly (1949)</p> </li> <li> <p>\"Modern\" Programming Languages (high level) Abstract, human-readable languages designed to be portable and easier to write.     Compiled or interpreted into lower-level code.  Examples:  C (1970),  Java (1995), Python (1991), JavaScript (1995) </p> </li> </ol>"},{"location":"wk_one/#multilevel-machines","title":"Multilevel Machines","text":"<ol> <li>Digital Logic Level </li> <li>Built from basic logic gates (AND, OR, NOT).  </li> <li> <p>These gates form circuits that make up components like CPU and memory.  </p> </li> <li> <p>Microarchitecture Level </p> </li> <li>Executes instructions using hardware components: ALU, registers, microprograms, memory.  </li> <li>A microprogram controls how instructions are executed.  </li> <li> <p>Represents the actual organization of the CPU at the circuit level.  </p> </li> <li> <p>Instruction Set Architecture (ISA) Level </p> </li> <li>Defines the set of machine instructions available (e.g., <code>LOAD</code>, <code>ADD</code>, <code>STORE</code>).  </li> <li>Independent of how the CPU actually implements them.  </li> <li> <p>Analogy: Like a menu in a restaurant \u2014 lists the \u201cdishes\u201d (operations) you can order, but not how they\u2019re cooked.  </p> </li> <li> <p>Operating System Machine Level </p> </li> <li>Main duties: memory management, process execution, and system resource protection.  </li> <li>Provides abstraction to simplify programming.  </li> <li>Assembly instructions generally pass through this level unchanged.  </li> <li> <p>Some interpretation happens here, as the OS manages low-level execution details.  </p> </li> <li> <p>Assembly Language Level </p> </li> <li>Human-readable mnemonics (e.g., <code>MOV</code>, <code>ADD</code>).  </li> <li>Harder to use \u2014 even simple programs require many lines.  </li> <li> <p>Translated into machine code by an assembler.  </p> </li> <li> <p>Problem-Oriented Language Level (High-Level Languages) </p> </li> <li>Includes languages like C, Java, Python.  </li> <li>Easier for humans to read, write, and maintain.  </li> <li>Compilers or interpreters convert these programs into assembly/machine code.  </li> </ol>"},{"location":"wk_one/#hardware-vs-software-and-control-units","title":"Hardware vs Software and Control Units","text":"<p>Anything that can be done with software can also be done with hardware, and vice versa (functionality).</p> <p>Hardware is generally faster and more expensive.</p>"},{"location":"wk_one/#control-unit-microprogrammed-vs-hardwired","title":"Control Unit: Microprogrammed vs Hardwired","text":"<p>The Control Unit (CU) generates the control signals that tell the CPU\u2019s datapath (ALU, registers, memory, etc.) what to do when executing instructions.</p>"},{"location":"wk_one/#microprogrammed-control-unit","title":"Microprogrammed Control Unit","text":"<ul> <li>Software-based control: Control signals are stored in a special memory (control memory, often ROM).  </li> <li>A microprogram is a sequence of microinstructions that generate the necessary control signals.  </li> <li>Execution = fetching and running these microinstructions in sequence.  </li> <li>Advantages:</li> <li>Easy to modify or extend (new instructions can be added by changing the microprogram).  </li> <li>Flexible and easier to design.  </li> <li>Disadvantages:</li> <li>Slower than hardwired control, since every instruction is broken into microinstructions that must be fetched and interpreted.  </li> </ul> <p>Example (slides): - Microprogram (P1): LEDs moving to the right. - Microprogram (P2): LEDs moving to the left. - Stored in ROM, and switching the program changes the behavior.</p>"},{"location":"wk_one/#hardwired-control-unit","title":"Hardwired Control Unit","text":"<ul> <li>Hardware-based control: Control signals are generated directly by fixed logic circuits.  </li> <li>No control memory \u2014 logic gates are wired to decode the opcode and trigger control signals.  </li> <li>Advantages:</li> <li>Much faster (signals generated directly by circuits).  </li> <li>Disadvantages:</li> <li>Inflexible \u2014 changing the instruction set requires redesigning the hardware.  </li> <li>More complex design as instruction sets grow.  </li> </ul>"},{"location":"wk_one/#comparison-table","title":"Comparison Table","text":"Aspect Microprogrammed CU Hardwired CU Implementation Control memory + microinstructions Fixed logic circuits Flexibility Easy to modify, new instructions easy Difficult to change Speed Slower (extra step: microinstruction) Faster (direct hardware) Complexity Simpler design More complex for large ISAs"},{"location":"wk_one/#historical-context","title":"Historical Context","text":"<ul> <li>Early computers: Direct hardwired execution.  </li> <li>Mid-generation: Microprogramming introduced to simplify control of complex instruction sets.  </li> <li>Modern trend: Moving back toward hardwired (or simplified ISAs) because microprogramming slows down execution.  </li> </ul>"},{"location":"wk_one/#computer-architecture_1","title":"Computer Architecture","text":""},{"location":"wk_one/#computer-generations","title":"Computer Generations","text":"<ul> <li>Zeroth Generation (1642 \u2013 1945): Mechanical Computers (e.g., Pascal's calculator).</li> <li>First Generation (1945 \u2013 1955): Vacuum Tubes (e.g., ENIAC \u2013 large,   power-hungry, first electronic general-purpose computer). * Von Neumann   Architecture (1945): Both data and program stored in memory (still the basis   for most digital computers).</li> <li>Second Generation (1955 \u2013 1965): Transistors (e.g., IBM 7094, PDP-8 with a   single bus/omnibus). Smaller, faster, cheaper.</li> <li>Third Generation (1965 \u2013 1980): Integrated Circuits (IC) (e.g., IBM 360).  Dozens of transistors on a single chip, leading to even smaller, faster, and cheaper computers.</li> <li>Fourth Generation (1980 \u2013 ?): Very Large Scale Integration (VLSI) (e.g.,   Intel CPUs). Millions of transistors on a single chip.</li> </ul>"},{"location":"wk_one/#moores-law","title":"Moore's Law","text":"<ul> <li>Gordon Moore (Intel, 1965).  </li> <li>Transistors on a chip roughly double every ~2 years.  </li> <li>Result: smaller, faster, cheaper computers.  </li> <li>Recently slowing due to physical limits.</li> </ul>"},{"location":"wk_one/#harvard-vs-von-neumann-architecture","title":"Harvard vs. Von Neumann Architecture","text":"<ul> <li>Harvard Architecture: <ul> <li>Separate memory for data and code.</li> <li>Two separate data paths for instructions and data. </li> <li>Faster (can access instructions and data simultaneously). </li> <li>Used in microcontrollers, DSPs. </li> <li>More complex design.</li> </ul> </li> <li>Von Neumann Architecture: <ul> <li>Shared memory for data and code. </li> <li>One shared data path for both. </li> <li>Slower (one access at a time). </li> <li>Used in general-purpose computers (PCs, laptops). </li> <li>Simpler design.</li> </ul> </li> </ul>"},{"location":"wk_one/#instruction-set-architectures-isas","title":"Instruction Set Architectures (ISAs)","text":"<p>An Instruction Set Architecture (ISA) defines the set of instructions that a CPU can execute. Different families of processors use different ISAs, optimized for different purposes.</p>"},{"location":"wk_one/#x86-architecture","title":"x86 Architecture","text":"<ul> <li>Originated with Intel 8086 (1978).</li> <li>Complex Instruction Set Computer (CISC) \u2013 many specialized instructions.</li> <li>Dominant in personal computers and servers.</li> <li>High backward compatibility (can still run very old code).</li> <li>Large, complex instruction set with advanced microarchitectural optimizations.</li> </ul>"},{"location":"wk_one/#arm-architecture","title":"ARM Architecture","text":"<ul> <li>First appeared in Acorn Archimedes (1987), later spun off as ARM Holdings.</li> <li>Reduced Instruction Set Computer (RISC) \u2013 small, simple set of instructions.</li> <li>Used in mobile devices, tablets, embedded systems, and increasingly laptops and servers (e.g., Apple M1/M2, AWS Graviton).</li> <li>High performance per watt (very energy efficient).</li> <li>Scales from tiny microcontrollers to high-end processors.</li> </ul>"},{"location":"wk_one/#avr-architecture","title":"AVR Architecture","text":"<ul> <li>Developed in 1996 (Norwegian Institute of Technology, later Atmel).</li> <li>RISC-based 8-bit microcontroller ISA.</li> <li>Widely used in embedded systems and Arduino boards.</li> <li>Small, low-power, inexpensive.</li> <li>Integrates Flash, EEPROM, and RAM on the same chip.</li> </ul>"},{"location":"wk_one/#comparison-table_1","title":"Comparison Table","text":"Feature x86 (CISC) ARM (RISC) AVR (RISC) First Release 1978 (Intel 8086) 1987 (Acorn Archimedes) 1996 (Atmel) Instruction Set Large, complex Small, simple Small, simple (8-bit) Main Usage PCs, laptops, servers Mobile, tablets, servers, IoT Embedded, Arduino Efficiency High performance, less efficient per watt Very energy efficient Extremely low power Cost/Scale Expensive, high complexity Scales across many devices Low cost, hobbyist friendly"},{"location":"wk_three/","title":"Boolean Algebra, Logic Simplification, K-Maps, and Logic Gates","text":"<p>These notes summarize the key concepts needed to understand Boolean expressions, simplification methods, truth tables, Karnaugh maps, and the design and interpretation of logic circuits.</p>"},{"location":"wk_three/#boolean-algebra-basics","title":"Boolean Algebra Basics","text":"<p>Boolean algebra deals with binary values and logic operations.</p> Concept Description Variables A, B, C, ... Values 0 (false), 1 (true) Functions F(A,B,C), G(A,B), ... Operations NOT (A'), AND (A\u00b7B), OR (A+B), XOR (A\u2295B) Examples of Boolean expressions <p>A\u00b7B A + B A'(B + C) A \u2295 B</p>"},{"location":"wk_three/#truth-tables","title":"Truth Tables","text":"<p>A truth table lists all possible input combinations and the resulting output.</p> Example Truth Table for AND A B A\u00b7B 0 0 0 0 1 0 1 0 0 1 1 1"},{"location":"wk_three/#boolean-identities-simplification-rules","title":"Boolean Identities (Simplification Rules)","text":"Rule Identity Complement A + A' = 1, A\u00b7A' = 0 Identity A + 0 = A, A\u00b71 = A Null A + 1 = 1, A\u00b70 = 0 Idempotent A + A = A, A\u00b7A = A De Morgan (A+B)' = A'\u00b7B', (A\u00b7B)' = A' + B' <p>Use these identities to reduce expressions and minimize gate usage.</p>"},{"location":"wk_three/#simplification-example","title":"Simplification Example","text":"<p>Simplify: F = A'B + AB' + AB</p> Step-by-Step Simplification <p>F = A'B + AB' + AB  = B(A' + A) + AB'  = B(1) + AB'  = B + AB'  = (B + A)(B + B')  = A + B</p> <p>Final Answer: F = A + B</p>"},{"location":"wk_three/#canonical-forms","title":"Canonical Forms","text":""},{"location":"wk_three/#sum-of-products-sop","title":"Sum of Products (SOP)","text":"<ul> <li>Use rows in truth table where F = 1</li> <li>Form minterms (AND of input variables)</li> <li>OR them together</li> </ul>"},{"location":"wk_three/#product-of-sums-pos","title":"Product of Sums (POS)","text":"<ul> <li>Use rows in truth table where F = 0</li> <li>Form maxterms (OR of input variables)</li> <li>AND them together</li> </ul>"},{"location":"wk_three/#karnaugh-maps-k-maps","title":"Karnaugh Maps (K-Maps)","text":"<p>K-maps are visual tools for simplifying Boolean expressions.</p>"},{"location":"wk_three/#rules","title":"Rules","text":"<ul> <li>Group 1s in sizes 1, 2, 4, 8, ...</li> <li>Groups must be rectangular</li> <li>Groups may wrap around edges</li> <li>Each 1 must be included in at least one group</li> <li>Larger groups produce simpler expressions</li> </ul>"},{"location":"wk_three/#k-map-example-3-variables-a-b-c","title":"K-Map Example (3 variables: A, B, C)","text":"<p>Truth table function values: F = 1 for m1, m3, m5, m7 (binary inputs 001, 011, 101, 111)</p> <p>K-Map:</p> AB \\ C 0 1 00 0 1 01 0 1 11 0 1 10 0 1 <p>Group the column where C = 1 \u2192 all 1\u2019s in one group.</p> <p>This means C remains; A and B vary \u2192 they drop out.</p> <p>Simplified Expression: F = C</p> Why this simplifies to C <p>C is the only input that is 1 in all grouped minterms. A and B change, so they do not appear in the final expression.</p>"},{"location":"wk_three/#logic-gates","title":"Logic Gates","text":"Gate Symbol Function NOT A' Inverts input AND A\u00b7B Output 1 if both inputs = 1 OR A + B Output 1 if any input = 1 XOR A \u2295 B Output 1 only if inputs differ NAND (A\u00b7B)' Inverted AND NOR (A + B)' Inverted OR"},{"location":"wk_two/","title":"Week 2","text":""},{"location":"wk_two/#data-representation-number-systems","title":"Data Representation &amp; Number Systems","text":"<p>Computers operate using binary (base 2), so we often need to convert between number systems and represent integers and real numbers efficiently.</p>"},{"location":"wk_two/#number-bases","title":"Number Bases","text":"System Base Digits Used Example Decimal 10 0\u20139 245\u2081\u2080 Binary 2 0\u20131 111101\u2082 Octal 8 0\u20137 725\u2088 Hexadecimal 16 0\u20139, A\u2013F A3F\u2081\u2086"},{"location":"wk_two/#conversions-between-bases","title":"Conversions Between Bases","text":""},{"location":"wk_two/#decimal-binary-repeated-division-by-2","title":"Decimal \u2192 Binary (Repeated division by 2)","text":"<ol> <li>Divide by 2.</li> <li>Record remainder.</li> <li>Continue until quotient = 0.</li> <li>Binary result = remainders read bottom \u2192 top.</li> </ol> Example: 224\u2081\u2080 \u2192 Binary <pre><code>224 \u00f7 2 = 112    remainder 0\n112 \u00f7 2 = 56     remainder 0\n56 \u00f7 2 = 28      remainder 0\n28 \u00f7 2 = 14      remainder 0\n14 \u00f7 2 = 7       remainder 0\n7 \u00f7 2 = 3        remainder 1\n3 \u00f7 2 = 1        remainder 1\n1 \u00f7 2 = 0        remainder 1\n\n11100000\u2082   (comes from the remainders)\n</code></pre>"},{"location":"wk_two/#binary-decimal-positional-weighting","title":"Binary \u2192 Decimal (Positional weighting)","text":"\\[ (an\u2026a_3a_2a_1a_0)\\_2 = \\sum a_i \u00b7 2^i \\] Example: 1101\u2082 \u2192 Decimal <p><code>(1\u00d72\u00b3) + (1\u00d72\u00b2) + (0\u00d72\u00b9) + (1\u00d72\u2070) = 8 + 4 + 0 + 1 = 13\u2081\u2080</code></p>"},{"location":"wk_two/#binary-hexadecimal-group-by-4-bits","title":"Binary \u2194 Hexadecimal (Group by 4 bits)","text":"Example: Binary \u2192 Hex <p><code>1101 0110 1001\u2082 D    6    9 \u2192 D69\u2081\u2086</code></p> Example: Hex \u2192 Binary <p><code>A  F  2 1010 1111 0010\u2082</code></p>"},{"location":"wk_two/#representing-integers-in-binary","title":"Representing Integers in Binary","text":""},{"location":"wk_two/#unsigned-integers","title":"Unsigned Integers","text":"<p>With N bits, values range from: [ 0 \\text{ to } (2^N - 1) ]</p> Bits Range 8-bit 0 \u2192 255 16-bit 0 \u2192 65,535 32-bit 0 \u2192 ~4.29 billion"},{"location":"wk_two/#signed-integers-twos-complement","title":"Signed Integers (Two\u2019s Complement)","text":"<p>To negate a number:</p> <ol> <li>Invert each bit.</li> <li>Add 1.</li> </ol> Example: Represent \u221224\u2081\u2080 <pre><code>+24 = 00011000\u2082\ninvert \u2192 11100111\u2082\n+1 \u2192 11101000\u2082\n\u2192 \u221224 = 11101000\u2082\n</code></pre>"},{"location":"wk_two/#twos-complement-integer-range","title":"Two\u2019s Complement Integer Range","text":"\\[ -(2^{N-1}) \\text{ to } (2^{N-1} - 1) \\] Bits Range 8-bit \u2212128 \u2192 +127 16-bit \u221232768 \u2192 +32767"},{"location":"wk_two/#subtraction-using-twos-complement","title":"Subtraction Using Two\u2019s Complement","text":"\\[ a - b = a + (-b) \\] Example: 3 \u2212 13 <pre><code>3 = 00000011\n13 = 00001101\n\n-13 = invert + 1 = 11110011\n\n00000011\n+11110011\n----------\n11110110 = \u221210\u2081\u2080\n</code></pre>"},{"location":"wk_two/#floating-point-representation-ieee-754","title":"Floating Point Representation (IEEE 754)","text":"<p>Real numbers are stored in normalized form:</p> \\[ (-1)^S \u00b7 (1.F) \u00b7 2^E \\] <p>Where:</p> <ul> <li>S = sign bit</li> <li>F = fraction (mantissa)</li> <li>E = exponent (stored using a bias)</li> </ul> Precision Total Bits Sign Exponent Fraction Bias Single (float) 32 1 8 23 127 Double (double) 64 1 11 52 1023 <p>Exponent stored as: [ E_b = E + \\text{bias} ]</p>"},{"location":"wk_two/#converting-fractions-to-binary","title":"Converting Fractions to Binary","text":"Example: 0.75\u2081\u2080 \u2192 Binary <p><code>0.75 \u00d7 2 = 1.5 \u2192 1 0.50 \u00d7 2 = 1.0 \u2192 1 \u2192 0.11\u2082</code></p>"},{"location":"wk_two/#full-ieee-754-encoding-example","title":"Full IEEE 754 Encoding Example","text":"<p>Convert \u22120.75\u2081\u2080 to single precision:</p> <ol> <li>Convert to binary:    0.75 = 0.11\u2082 = 1.1\u2082 \u00d7 2\u207b\u00b9</li> <li>Sign bit = 1 (negative)</li> <li>Exponent = \u22121 \u2192 E_b = 127 \u2212 1 = 126 = 01111110\u2082</li> <li>Fraction = 10000000000000000000000</li> </ol> <p>Final 32-bit value:</p> <pre><code>1 01111110 10000000000000000000000\n</code></pre>"},{"location":"wk_two/#quick-reference-summary","title":"Quick Reference Summary","text":"Type Form Notes Two\u2019s Complement invert bits + 1 Only one zero &amp; supports direct subtraction Float Normalize 1.F \u00d7 2^E Only one leading 1 (implicit) IEEE Exponent stored = E + bias bias = 127 (float), 1023 (double) Binary \u2194 Hex Group bits into 4 Fast conversion"}]}